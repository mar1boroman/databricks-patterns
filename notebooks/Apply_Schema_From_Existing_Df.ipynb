{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, TimestampType\nfrom datetime import datetime"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Imports & setting up initial data frame","showTitle":true,"inputWidgets":{},"nuid":"9e78230d-3c36-4a78-8095-e0bccd15d408"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data1 = [\n    [1, \"John1\", \"Doe1\", datetime.now(), 31.5],\n    [2, \"John2\", \"Doe2\", datetime.now(), 37.5],\n    [3, \"John3\", \"Doe3\", datetime.now(), 62.5],\n    [4, \"John4\", \"Doe4\", datetime.now(), 74.5]\n]\n\ndata2 = [\n    ['1', \"Jane1\", \"Doe1\", '10:05:00.00', '31.5'],\n    ['2', \"Jane2\", \"Doe2\", '13:10:00.12', '37.5'],\n    ['3', \"Jane3\", \"Doe3\", '18:30:00.30', '62.5'],\n    ['4', \"Jane4\", \"Doe4\", '21:45:00.44', '74.5']\n]\n\ninit_schema = StructType([\n    StructField(\"id\", IntegerType(), True),\n    StructField(\"FirstName\", StringType(), True),\n    StructField(\"LastName\", StringType(), True),\n    StructField(\"SnapshotTime\", TimestampType(), True),\n    StructField(\"Metric\", FloatType(), True),\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a610888-0fbe-48f3-ae92-9b3d3ed5cfab"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["init_df_with_schema = spark.createDataFrame(data=data1, schema=init_schema)\ninit_df_with_schema.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Initial Dataframe","showTitle":true,"inputWidgets":{},"nuid":"6d399e0e-5f15-42e5-86a4-c3a63ae726b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: StructType(List(StructField(id,IntegerType,true),StructField(FirstName,StringType,true),StructField(LastName,StringType,true),StructField(SnapshotTime,TimestampType,true),StructField(Metric,FloatType,true)))","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: StructType(List(StructField(id,IntegerType,true),StructField(FirstName,StringType,true),StructField(LastName,StringType,true),StructField(SnapshotTime,TimestampType,true),StructField(Metric,FloatType,true)))"]}}],"execution_count":0},{"cell_type":"code","source":["new_df_without_schema = spark.createDataFrame(data2,[\"id\", \"FirstName\", \"LastName\", \"SnapshotTime\", \"Metric\"])\nnew_df_without_schema.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"New DataFrame which only has column names, but schema is inferred","showTitle":true,"inputWidgets":{},"nuid":"48f2c189-3388-42d9-9b26-816bb3aca9b3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[5]: StructType(List(StructField(id,StringType,true),StructField(FirstName,StringType,true),StructField(LastName,StringType,true),StructField(SnapshotTime,StringType,true),StructField(Metric,StringType,true)))","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[5]: StructType(List(StructField(id,StringType,true),StructField(FirstName,StringType,true),StructField(LastName,StringType,true),StructField(SnapshotTime,StringType,true),StructField(Metric,StringType,true)))"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col\nfor metadata in init_df_with_schema.dtypes:\n    new_df_without_schema = new_df_without_schema.withColumn(metadata[0], col(metadata[0]).cast(metadata[1]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Using the Initial DataFrame to cast the columns of the New DataFrame","showTitle":true,"inputWidgets":{},"nuid":"fb89ed5b-744a-4554-a4f3-e51770bab375"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if(new_df_without_schema.schema == init_df_with_schema.schema):\n    print(\"Schema matches!\")\nelse:\n    print(\"Schema does not match\")\n    print(new_df_without_schema.schema)\n    print('***************************')\n    print(init_df_with_schema.schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Check if the Schema for the New DataFrame matches the Initial DataFrame","showTitle":true,"inputWidgets":{},"nuid":"006253b9-b28a-4bc0-ae60-75e7ef8d3b14"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Schema matches!\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Schema matches!\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Apply_Schema_From_Existing_Df","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3582725276168850}},"nbformat":4,"nbformat_minor":0}
